{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This notebook demonstrates how to run the defect detection pipeline in different playback modes like file and live capture. Live capture has normal mode & demo mode. Normal mode runs at full fps & demo mode is restricted to 4fps. Live images are captured from the MIPI device, then performs defect detection acceleration using Vitis Vision library. The defect results text will be embedded along with the accelerator output image and sends out to 4K display.\n",
    "\n",
    "Please refer to the tutorial of the SOM Starter Kit Defect Detection document for detailed HW/SW architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization\n",
    "Import all python modules required for this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "gi.require_version('GstVideo', '1.0')\n",
    "gi.require_version('GIRepository', '2.0')\n",
    "from gi.repository import GObject, Gst, GstVideo, GLib, GIRepository\n",
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainloop = GLib.MainLoop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the modetest command to configure the mixer IP for 4K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwpath=\"/dev/dri/by-path/\"\n",
    "fwfilename=\"platform-b0010000.v_mix-card\"\n",
    "if os.path.exists(fwpath) and fwfilename in os.listdir(fwpath):\n",
    "    out = subprocess.check_output('modetest -M xlnx -D B0010000.v_mix -s 52@40:3840x2160@NV16',shell=True)\n",
    "    print(out.decode('ascii'))\n",
    "else:    \n",
    "    print(\"Defect detection Firmware not loaded, Run 'xmutil loadapp kv260-defect-detect' \")  \n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Construct the String Representation of GStreamer Pipeline\n",
    "## The get_media_by_device function returns the matching media node for a given video capture source.<br>\n",
    "## The following sources are supported in this notebook:\n",
    "\n",
    "* mipi : platform1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        'mipi' : 'vcap_csi',\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the playback variable to switch between filesrc/media soruce <br>\n",
    "## Available options:\n",
    "## 0 ==> File input and file sink\n",
    "## 1 ==> Live normal mode. Live source and display out normal mode\n",
    "## 2 ==> Live Demo mode. Live source and display out\n",
    "## 3 ==> File In Display Out\n",
    "## 4 ==> Live In and File Out\n",
    "## 5 ==> File In Display Out - Demo Mode\n",
    "## Change the filesinkpath to store the different stages output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for file input and file sink\n",
    "# 1 for Live normal mode\n",
    "# 2 for Live Demo mode\n",
    "# 3 File In Display Out\n",
    "# 4 Live In and File Out\n",
    "# 5 File In Display Out Demo Mode\n",
    "playback = 1\n",
    "filesinkpath=\"/home\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the source by calling get_media_dev_by_name()\n",
    "## For file source copy the input video file to any rootfs path & update the location variable accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"mipi\"\n",
    "\n",
    "if playback == 1 or playback == 2 or playback == 4:#media src bin\n",
    "    media_device = get_media_dev_by_name(source)\n",
    "    print(media_device)\n",
    "    if media_device is None:\n",
    "        raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered and correct Defect detection firmware is loaded.')\n",
    "    # 'ar0144-sensor-calib.sh' script will set the default sensor calibration paramters\n",
    "    # User can do the calibration for their test environment & update the values in the script\n",
    "    os.system('ar0144-sensor-calib.sh '+media_device)\n",
    "\n",
    "src=\"\"\n",
    "\n",
    "if playback == 1 or playback == 2 or playback == 4:#media src bin\n",
    "    src += \"mediasrcbin media-device=\" + media_device\n",
    "elif playback == 0 or playback == 3 or playback == 5: # file src\n",
    "    src += \"filesrc location=/home/input_video.y8 blocksize=1024000\"    \n",
    "\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the real pipeline string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configuration directory for VVAS plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confdir=\"/opt/xilinx/kv260-defect-detect/share/vvas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the caps.\n",
    "User can change the resolution and framerate here.\n",
    "\n",
    "In case videosrc doesn't support GRAY8 format, adjust the pipeline to fit with followning elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if playback == 0 or playback == 1 or playback == 3 or playback == 4:\n",
    "    pip=src + ' ! video/x-raw, width=1280, height=800, format=GRAY8, framerate=60/1 '\n",
    "elif playback == 2:\n",
    "    pip=src + ' ! video/x-raw, width=1280, height=800, format=GRAY8, framerate=4/1 '\n",
    "elif playback == 5:    \n",
    "    pip=src + ' ! rawvideoparse use-sink-caps=false width=1280 height=800 format=gray8 framerate=4/1 '\n",
    "print(pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the live capture pipeline.\n",
    "vvas_xfilter kconfig=\"{confdir}/otsu-accelarator.json\" is configure the kernel name, xclbin path, debug level. <br>\n",
    "preprocess-accelarator.json to configure kernel name, xclbin path, threshold value & max value. <br>\n",
    "cca-accelarator.json is to configure kernel name, xclbin path, debug level. <br>\n",
    "text2overlay.json is to configure defect threshold, x/y offset of the text, font size, font. <br>\n",
    "\n",
    "Detailed configuration can be found in the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += ' ! tee name=t_src t_src. ! queue ! vvas_xfilter kernels-config={confdir}/otsu-accelarator.json ! vvas_xfilter kernels-config={confdir}/preprocess-accelarator.json ! tee name=t_pre t_pre. ! queue ! vvas_xfilter kernels-config={confdir}/cca-accelarator.json ! vvas_xfilter kernels-config={confdir}/text2overlay.json '.format(confdir=confdir)\n",
    "\n",
    "# For demo mode\n",
    "if playback == 2:\n",
    "    pip += ' ! videorate ! video/x-raw, width=1280, height=800, format=GRAY8, framerate=4/1 '\n",
    "    \n",
    "if playback == 0 or playback == 4:\n",
    "    pip += \"! filesink  location={path}/final.y8\".format(path=filesinkpath)\n",
    "elif playback == 1 or playback == 2 or playback == 3 or playback == 5:\n",
    "    pip += '! perf ! kmssink bus-id=B0010000.v_mix plane-id=34 render-rectangle=\"<2560,680,1280,800>\"'\n",
    "\n",
    "pip += ' t_src. ! queue '\n",
    "\n",
    "# For demo mode\n",
    "if playback == 2:\n",
    "    pip += ' ! videorate ! video/x-raw, width=1280, height=800, format=GRAY8, framerate=4/1 '\n",
    "\n",
    "if playback == 0 or playback == 4:\n",
    "    pip += \"! filesink location={path}/raw_src.y8\".format(path=filesinkpath)\n",
    "elif playback == 1 or playback == 2 or playback == 3 or playback == 5:\n",
    "    pip += '! perf ! kmssink bus-id=B0010000.v_mix  plane-id=35 render-rectangle=\"<0,680,1280,800>\"'\n",
    "\n",
    "pip += ' t_pre. ! queue '\n",
    "\n",
    "# For demo mode\n",
    "if playback == 2:\n",
    "    pip += ' ! videorate ! video/x-raw, width=1280, height=800, format=GRAY8, framerate=4/1 '\n",
    "\n",
    "if playback == 0 or playback == 4:\n",
    "    pip += \"! filesink location={path}/pre-process.y8 async=false \".format(path=filesinkpath)\n",
    "elif playback == 1 or playback == 2 or playback == 3 or playback == 5:\n",
    "    pip += '! perf ! kmssink bus-id=B0010000.v_mix plane-id=36 render-rectangle=\"<1280,680,1280,800>\" async=false '.format(confdir=confdir)\n",
    "\n",
    "print(pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Gst.parse_launch(pip)\n",
    "pipe.set_state(Gst.State.PLAYING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = GLib.MainLoop()\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    pipe.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary\n",
    "The Jupyter application shows how to:\n",
    "\n",
    "1. Create a GStreamer pipeline which utilize the VVAS framework to call Vitis Vision Library to do defect detection on the live mango images, and embed the defect result on the final image from accelerator.\n",
    "3. Live capture is supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019-2022 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
